{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import multiprocessing as mp\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from heapq import nlargest\n",
    "\n",
    "import sys\n",
    "# User defined Imports ugly python import syntax >:(\n",
    "sys.path.append('./Preprocess')\n",
    "from dataJoin import joinData\n",
    "from parallelLoad import parallelLoad\n",
    "from preprocess import CustomAnalyzer, doFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk7.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk2.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk12.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk4.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk6.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk14.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk9.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk15.csv\n",
      "Starting the pooling...\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk8.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk11.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk13.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk10.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk3.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk1.csv\n",
      "Loading the file:  ./data/traditionalSpamBotsChunks1/tweetsBots_chunk5.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk107.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk253.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk225.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk207.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk15.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk27.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk242.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk115.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk152.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk216.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk193.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk12.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk157.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk226.csv\n",
      "Starting the pooling...\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk261.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk243.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk176.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk274.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk73.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk156.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk230.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk277.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk38.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk234.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk208.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk30.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk5.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk126.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk154.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk203.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk166.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk151.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk250.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk246.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk10.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk270.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk49.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk113.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk89.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk144.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk249.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk124.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk202.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk223.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk169.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk119.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk92.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk147.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk222.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk209.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk82.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk263.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk136.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk268.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk78.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk239.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk35.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk20.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk137.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk256.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk177.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk83.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk265.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk260.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk21.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk116.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk55.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk206.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk283.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk282.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk244.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk245.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk33.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk106.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk71.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk45.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk68.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk153.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk70.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk172.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk192.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk178.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk160.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk43.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk164.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk57.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk195.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk13.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk4.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk130.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk278.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk148.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk227.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk196.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk34.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk118.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk56.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk39.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk97.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk182.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk17.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk3.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk219.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk183.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk238.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk104.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk41.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk123.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk18.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk22.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk210.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk94.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk173.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk74.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk2.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk171.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk214.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk65.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk275.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk179.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk167.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk189.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk29.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk200.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk11.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk6.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk87.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk221.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk135.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk188.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk91.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk237.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk112.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk159.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk269.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk284.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk240.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk142.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk145.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk80.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk224.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk201.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk211.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk233.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk62.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk114.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk16.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk79.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk231.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk174.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk271.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk122.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk59.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk95.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk140.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk247.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk139.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk252.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk131.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk8.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk7.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk48.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk141.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk31.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk64.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk117.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk259.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk266.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk281.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk205.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk235.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk25.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk248.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk86.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk146.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk276.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk165.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk264.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk67.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk191.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk212.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk32.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk88.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk60.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk111.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk241.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk194.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk132.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk28.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk158.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk110.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk26.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk134.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk120.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk51.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk163.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk162.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk255.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk150.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk50.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk190.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk133.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk40.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk42.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk204.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk54.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk257.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk213.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk52.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk63.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk258.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk155.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk129.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk72.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk273.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk23.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk229.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk168.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk44.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk184.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk128.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk272.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk218.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk58.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk101.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk108.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk149.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk1.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk185.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk228.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk138.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk46.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk81.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk280.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk103.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk125.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk14.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk77.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk98.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk96.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk105.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk181.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk198.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk75.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk84.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk236.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk215.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk199.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk85.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk24.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk220.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk187.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk180.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk143.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk9.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk90.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk251.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk175.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk102.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk66.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk186.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk109.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk262.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk254.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk279.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk100.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk76.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk217.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk121.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk197.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk161.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk232.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk99.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk37.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk61.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk170.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk53.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk267.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk127.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk69.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk93.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk47.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk36.csv\n",
      "Loading the file:  ./data/genuineTweetsChunks/tweetsGenuine_chunk19.csv\n",
      "Joining data...\n",
      "-------Start Join-------\n",
      "-------End Join-------\n",
      "\n",
      "Read 40000 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./Preprocess/dataJoin.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  botData['bot'] = 1\n",
      "./Preprocess/dataJoin.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  genuineData['bot'] = 0\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "print('Loading data...')\n",
    "\n",
    "# Start Data loading using paralelization parallelLoad(route_to_files) function!\n",
    "filesRoute = './data/traditionalSpamBotsChunks1/'\n",
    "botData = parallelLoad(filesRoute)\n",
    "filesRoute = './data/genuineTweetsChunks/'\n",
    "genuineData = parallelLoad(filesRoute)\n",
    "\n",
    "print('Joining data...')\n",
    "df = joinData(botData.head(20000), genuineData.head(20000))\n",
    "\n",
    "# See how many tweets we read\n",
    "print(\"Read {0:d} tweets\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 26)\n",
      "['id', 'text', 'source', 'user_id', 'truncated', 'in_reply_to_status_id', 'in_reply_to_user_id', 'in_reply_to_screen_name', 'retweeted_status_id', 'geo', 'place', 'contributors', 'retweet_count', 'reply_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'num_hashtags', 'num_urls', 'num_mentions', 'created_at', 'timestamp', 'crawled_at', 'updated', 'bot']\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>updated</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21352627412</td>\n",
       "      <td>Winning isnt everything, its the only thing. R...</td>\n",
       "      <td>&lt;a href=\"http://www.socialoomph.com\" rel=\"nofo...</td>\n",
       "      <td>69744581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1281999866000L</td>\n",
       "      <td>2010-08-17 01:04:26</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>2014-04-16 23:58:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21352276280</td>\n",
       "      <td>http://bit.ly/pro2020 This is a NO Brainer, tr...</td>\n",
       "      <td>&lt;a href=\"http://www.socialoomph.com\" rel=\"nofo...</td>\n",
       "      <td>69744581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1281999559000L</td>\n",
       "      <td>2010-08-17 00:59:19</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>2014-04-16 23:58:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21351076660</td>\n",
       "      <td>Winning is not everything, but the effort to w...</td>\n",
       "      <td>&lt;a href=\"http://www.socialoomph.com\" rel=\"nofo...</td>\n",
       "      <td>69744581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1281998482000L</td>\n",
       "      <td>2010-08-17 00:41:22</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>2014-04-16 23:58:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21350081764</td>\n",
       "      <td>One of my top mentors, so glad I joined him, s...</td>\n",
       "      <td>&lt;a href=\"http://www.socialoomph.com\" rel=\"nofo...</td>\n",
       "      <td>69744581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1281997577000L</td>\n",
       "      <td>2010-08-17 00:26:17</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>2014-04-16 23:58:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21349577659</td>\n",
       "      <td>Winning is everything. The only ones who remem...</td>\n",
       "      <td>&lt;a href=\"http://www.socialoomph.com\" rel=\"nofo...</td>\n",
       "      <td>69744581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1281997111000L</td>\n",
       "      <td>2010-08-17 00:18:31</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>2014-04-16 23:58:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "0  21352627412  Winning isnt everything, its the only thing. R...   \n",
       "1  21352276280  http://bit.ly/pro2020 This is a NO Brainer, tr...   \n",
       "2  21351076660  Winning is not everything, but the effort to w...   \n",
       "3  21350081764  One of my top mentors, so glad I joined him, s...   \n",
       "4  21349577659  Winning is everything. The only ones who remem...   \n",
       "\n",
       "                                              source     user_id  truncated  \\\n",
       "0  <a href=\"http://www.socialoomph.com\" rel=\"nofo...  69744581.0        NaN   \n",
       "1  <a href=\"http://www.socialoomph.com\" rel=\"nofo...  69744581.0        NaN   \n",
       "2  <a href=\"http://www.socialoomph.com\" rel=\"nofo...  69744581.0        NaN   \n",
       "3  <a href=\"http://www.socialoomph.com\" rel=\"nofo...  69744581.0        NaN   \n",
       "4  <a href=\"http://www.socialoomph.com\" rel=\"nofo...  69744581.0        NaN   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_user_id in_reply_to_screen_name  \\\n",
       "0                    0.0                  0.0                     NaN   \n",
       "1                    0.0                  0.0                     NaN   \n",
       "2                    0.0                  0.0                     NaN   \n",
       "3                    0.0                  0.0                     NaN   \n",
       "4                    0.0                  0.0                     NaN   \n",
       "\n",
       "   retweeted_status_id  geo ...  retweeted  possibly_sensitive  num_hashtags  \\\n",
       "0                  0.0  NaN ...        NaN                 NaN           0.0   \n",
       "1                  0.0  NaN ...        NaN                 NaN           0.0   \n",
       "2                  0.0  NaN ...        NaN                 NaN           0.0   \n",
       "3                  0.0  NaN ...        NaN                 NaN           0.0   \n",
       "4                  0.0  NaN ...        NaN                 NaN           0.0   \n",
       "\n",
       "   num_urls  num_mentions      created_at            timestamp  \\\n",
       "0       0.0           0.0  1281999866000L  2010-08-17 01:04:26   \n",
       "1       1.0           0.0  1281999559000L  2010-08-17 00:59:19   \n",
       "2       0.0           0.0  1281998482000L  2010-08-17 00:41:22   \n",
       "3       1.0           0.0  1281997577000L  2010-08-17 00:26:17   \n",
       "4       0.0           0.0  1281997111000L  2010-08-17 00:18:31   \n",
       "\n",
       "            crawled_at              updated  bot  \n",
       "0  0000-00-00 00:00:00  2014-04-16 23:58:03    1  \n",
       "1  0000-00-00 00:00:00  2014-04-16 23:58:03    1  \n",
       "2  0000-00-00 00:00:00  2014-04-16 23:58:03    1  \n",
       "3  0000-00-00 00:00:00  2014-04-16 23:58:03    1  \n",
       "4  0000-00-00 00:00:00  2014-04-16 23:58:03    1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_vars=['place','num_hashtags','num_urls','num_mentions']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(df[var], prefix=var,prefix_sep='_',dummy_na=True)\n",
    "    data1=df.join(cat_list)\n",
    "    df=data1\n",
    "\n",
    "cat_vars=['place','num_hashtags','num_urls','num_mentions']\n",
    "data_vars=df.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'text', 'source', 'user_id', 'truncated',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id',\n",
       "       'in_reply_to_screen_name', 'retweeted_status_id', 'geo',\n",
       "       'contributors', 'retweet_count', 'reply_count', 'favorite_count',\n",
       "       'favorited', 'retweeted', 'possibly_sensitive', 'created_at',\n",
       "       'timestamp', 'crawled_at', 'updated', 'bot', 'place_Alabama, USA',\n",
       "       'place_Central Visayas, Republic of the Philippines',\n",
       "       'place_Hudson, FL', 'place_Lungsod ng Butuan, Caraga',\n",
       "       'place_Lungsod ng Cebu, Central Visayas',\n",
       "       'place_Lungsod ng Mandaue, Central Visayas', 'place_Nashville, TN',\n",
       "       'place_National Capital Region, Republic of the Philippines',\n",
       "       'place_Ottawa, Ontario', 'place_Rutherford, TN',\n",
       "       'place_Tennessee, USA', 'place_Verona, MS',\n",
       "       'place_Western Visayas, Republic of the Philippines', 'place_nan',\n",
       "       'num_hashtags_0.0', 'num_hashtags_1.0', 'num_hashtags_2.0',\n",
       "       'num_hashtags_3.0', 'num_hashtags_4.0', 'num_hashtags_5.0',\n",
       "       'num_hashtags_6.0', 'num_hashtags_8.0', 'num_hashtags_nan',\n",
       "       'num_urls_0.0', 'num_urls_1.0', 'num_urls_2.0', 'num_urls_3.0',\n",
       "       'num_urls_nan', 'num_mentions_0.0', 'num_mentions_1.0',\n",
       "       'num_mentions_2.0', 'num_mentions_3.0', 'num_mentions_4.0',\n",
       "       'num_mentions_5.0', 'num_mentions_6.0', 'num_mentions_7.0',\n",
       "       'num_mentions_8.0', 'num_mentions_9.0', 'num_mentions_10.0',\n",
       "       'num_mentions_11.0', 'num_mentions_nan'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final=df[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't covert text to float\n",
      "Couldn't covert source to float\n",
      "Couldn't covert in_reply_to_screen_name to float\n",
      "Couldn't covert created_at to float\n",
      "Couldn't covert timestamp to float\n",
      "Couldn't covert crawled_at to float\n",
      "Couldn't covert updated to float\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>place_Alabama, USA</th>\n",
       "      <th>place_Central Visayas, Republic of the Philippines</th>\n",
       "      <th>place_Hudson, FL</th>\n",
       "      <th>place_Lungsod ng Butuan, Caraga</th>\n",
       "      <th>...</th>\n",
       "      <th>num_mentions_3.0</th>\n",
       "      <th>num_mentions_4.0</th>\n",
       "      <th>num_mentions_5.0</th>\n",
       "      <th>num_mentions_6.0</th>\n",
       "      <th>num_mentions_7.0</th>\n",
       "      <th>num_mentions_8.0</th>\n",
       "      <th>num_mentions_9.0</th>\n",
       "      <th>num_mentions_10.0</th>\n",
       "      <th>num_mentions_11.0</th>\n",
       "      <th>num_mentions_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   in_reply_to_status_id  in_reply_to_user_id  retweeted_status_id  \\\n",
       "0                    0.0                  0.0                  0.0   \n",
       "1                    0.0                  0.0                  0.0   \n",
       "2                    0.0                  0.0                  0.0   \n",
       "3                    0.0                  0.0                  0.0   \n",
       "4                    0.0                  0.0                  0.0   \n",
       "\n",
       "   retweet_count  reply_count  favorite_count  place_Alabama, USA  \\\n",
       "0            0.0          0.0             0.0                   0   \n",
       "1            0.0          0.0             0.0                   0   \n",
       "2            0.0          0.0             0.0                   0   \n",
       "3            0.0          0.0             0.0                   0   \n",
       "4            0.0          0.0             0.0                   0   \n",
       "\n",
       "   place_Central Visayas, Republic of the Philippines  place_Hudson, FL  \\\n",
       "0                                                  0                  0   \n",
       "1                                                  0                  0   \n",
       "2                                                  0                  0   \n",
       "3                                                  0                  0   \n",
       "4                                                  0                  0   \n",
       "\n",
       "   place_Lungsod ng Butuan, Caraga        ...         num_mentions_3.0  \\\n",
       "0                                0        ...                        0   \n",
       "1                                0        ...                        0   \n",
       "2                                0        ...                        0   \n",
       "3                                0        ...                        0   \n",
       "4                                0        ...                        0   \n",
       "\n",
       "   num_mentions_4.0  num_mentions_5.0  num_mentions_6.0  num_mentions_7.0  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   num_mentions_8.0  num_mentions_9.0  num_mentions_10.0  num_mentions_11.0  \\\n",
       "0                 0                 0                  0                  0   \n",
       "1                 0                 0                  0                  0   \n",
       "2                 0                 0                  0                  0   \n",
       "3                 0                 0                  0                  0   \n",
       "4                 0                 0                  0                  0   \n",
       "\n",
       "   num_mentions_nan  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_final\n",
    "cols_to_remove = []\n",
    "\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        _ = df[col].astype(float)\n",
    "    except ValueError:\n",
    "        print('Couldn\\'t covert %s to float' % col)\n",
    "        cols_to_remove.append(col)\n",
    "        pass\n",
    "\n",
    "# keep only the columns in df that do not contain string\n",
    "data = df[[col for col in df.columns if col not in cols_to_remove]]\n",
    "data = data.drop(['bot','id','user_id'], axis=1)\n",
    "data = data.dropna(axis=1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/yifei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "[ 1  2  1  3  1 11 44 27 35 33 31 42 40 32 39 41 28 29 34 36 37  4  6  9\n",
      " 14 24 26 30 23 43 46  8  7 12 38 45  5 10 15 17 16 13 18 21 20 19 22 25\n",
      " 47]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(data, df.bot)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
